#pragma kernel BitonicSort
#pragma kernel MatrixTranspose

#define BITONIC_BLOCK_SIZE 512
#define TRANSPOSE_BLOCK_SIZE 16

struct CB
{
	uint level;
	uint levelMask;
	uint width;
	uint height;
};

struct KIP
{
	uint key;
	uint index;
};

StructuredBuffer<CB> Consts;
StructuredBuffer<KIP> Input;
RWStructuredBuffer<KIP> Data;

groupshared KIP shared_data[BITONIC_BLOCK_SIZE];

[numthreads(BITONIC_BLOCK_SIZE, 1, 1)]
void BitonicSort( uint3 Gid : SV_GroupID, 
				  uint3 DTid : SV_DispatchThreadID, 
				  uint3 GTid : SV_GroupThreadID, 
				  uint GI : SV_GroupIndex )
{
	shared_data[GI] = Data[DTid.x];
	GroupMemoryBarrierWithGroupSync();
	
	for (uint j = Consts[0].level >> 1 ; j > 0 ; j >>= 1)
	{
		KIP result;
		bool c1 = shared_data[GI & ~j].key <= shared_data[GI | j].key;
		bool c2 = (Consts[0].levelMask & DTid.x) != 0;
		if(c1==c2) {
			result = shared_data[GI ^ j];
		}
		else {
			result = shared_data[GI];
		}

		GroupMemoryBarrierWithGroupSync();
		shared_data[GI] = result;
		GroupMemoryBarrierWithGroupSync();
	}
	
	Data[DTid.x] = shared_data[GI];
}


groupshared KIP transpose_shared_data[TRANSPOSE_BLOCK_SIZE * TRANSPOSE_BLOCK_SIZE];

[numthreads(TRANSPOSE_BLOCK_SIZE, TRANSPOSE_BLOCK_SIZE, 1)]
void MatrixTranspose( uint3 Gid : SV_GroupID, 
					  uint3 DTid : SV_DispatchThreadID, 
					  uint3 GTid : SV_GroupThreadID, 
					  uint GI : SV_GroupIndex )
{
	transpose_shared_data[GI] = Input[DTid.y * Consts[0].width + DTid.x];
	GroupMemoryBarrierWithGroupSync();
	uint2 XY = DTid.yx - GTid.yx + GTid.xy;
	Data[XY.y * Consts[0].height + XY.x] = transpose_shared_data[GTid.x * TRANSPOSE_BLOCK_SIZE + GTid.y];
}
